{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bd5c5c",
   "metadata": {},
   "source": [
    "# Processing Signals with Pipelines\n",
    "\n",
    "Now that we have identified and/or generated several primitives for our signal feature generation, we would like to define a reusable *pipeline* for doing so. \n",
    "\n",
    "First, let's import the required libraries and functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fff2209",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sigpro\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sigpro.demo import _load_demo as get_demo\n",
    "from sigpro.demo import get_demo_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78484fc",
   "metadata": {},
   "source": [
    "\n",
    "## Defining Primitives\n",
    "\n",
    "Recall that we can obtain the list of available primitives with the `get_primitives` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dad1a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sigpro.SigPro',\n",
       " 'sigpro.aggregations.amplitude.statistical.crest_factor',\n",
       " 'sigpro.aggregations.amplitude.statistical.kurtosis',\n",
       " 'sigpro.aggregations.amplitude.statistical.mean',\n",
       " 'sigpro.aggregations.amplitude.statistical.rms',\n",
       " 'sigpro.aggregations.amplitude.statistical.skew',\n",
       " 'sigpro.aggregations.amplitude.statistical.std',\n",
       " 'sigpro.aggregations.amplitude.statistical.var',\n",
       " 'sigpro.aggregations.frequency.band.band_mean',\n",
       " 'sigpro.transformations.amplitude.identity.identity',\n",
       " 'sigpro.transformations.amplitude.spectrum.power_spectrum',\n",
       " 'sigpro.transformations.frequency.band.frequency_band',\n",
       " 'sigpro.transformations.frequency.fft.fft',\n",
       " 'sigpro.transformations.frequency.fft.fft_real',\n",
       " 'sigpro.transformations.frequency_time.stft.stft',\n",
       " 'sigpro.transformations.frequency_time.stft.stft_real']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sigpro import get_primitives\n",
    "\n",
    "get_primitives()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118862ab",
   "metadata": {},
   "source": [
    "In addition, we can also define our own custom primitives.\n",
    "\n",
    "## Building a Pipeline\n",
    "\n",
    "Letâ€™s go ahead and define a feature processing pipeline that sequentially applies the `identity`and `fft` transformations before applying the `std` aggregation. To pass these primitives into the signal processor, we must write each primitive as a dictionary with the following fields:\n",
    "\n",
    "- `name`: Name of the transformation / aggregation.\n",
    "- `primitive`: Name of the primitive to apply.\n",
    "- `init_params`: Dictionary containing the initializing parameters for the primitive. *\n",
    "\n",
    "Since we choose not to specify any initial parameters, we do not set `init_params` in these dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ab235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_transform = {'name': 'identity1',\n",
    "            'primitive': 'sigpro.transformations.amplitude.identity.identity'}\n",
    "\n",
    "fft_transform =  {'name': 'fft1',\n",
    "            'primitive': 'sigpro.transformations.frequency.fft.fft'}\n",
    "\n",
    "std_agg = {'name': 'std1',\n",
    "            'primitive': \"sigpro.aggregations.amplitude.statistical.std\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70be16d",
   "metadata": {},
   "source": [
    "\n",
    "We now define a new pipeline containing  the primitives we would like to apply. At minimum, we will need to pass in a list of transformations and a list of aggregations; the full list of available arguments is given below.\n",
    "\n",
    "- Inputs:\n",
    "    - `transformations (list)` : List of dictionaries containing the transformation primitives.\n",
    "    - `aggregations (list)`:  List of dictionaries containing the aggregation primitives.\n",
    "    - `values_column_name (str)`(optional):The name of the column that contains the signal values. Defaults to `'values'`.\n",
    "    - `keep_columns (Union[bool, list])`  (optional): Whether to keep non-feature columns in the output DataFrame or not. If a list of column names are passed, those columns are kept. Defaults to `False`.\n",
    "    - `input_is_dataframe (bool)` (optional): Whether the input is a pandas Dataframe. Defaults to `True`.\n",
    "\n",
    "Returning to the example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e59322d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = [identity_transform, fft_transform]\n",
    "\n",
    "aggregations = [std_agg]\n",
    "\n",
    "mypipeline = sigpro.SigPro(transformations, aggregations, values_column_name = 'yvalues', keep_columns = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dab5460",
   "metadata": {},
   "source": [
    "\n",
    "SigPro will proceed to build an `MLPipeline` that can be reused to build features.\n",
    "\n",
    "To check that `mypipeline` was defined correctly, we can check the input and output arguments with the `get_input_args` and `get_output_args` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1491f5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'readings', 'keyword': 'data', 'type': 'pandas.DataFrame'}, {'name': 'feature_columns', 'default': None, 'type': 'list'}]\n",
      "[{'name': 'readings', 'type': 'pandas.DataFrame'}, {'name': 'feature_columns', 'type': 'list'}]\n"
     ]
    }
   ],
   "source": [
    "input_args = mypipeline.get_input_args()\n",
    "output_args = mypipeline.get_output_args()\n",
    "\n",
    "print(input_args)\n",
    "print(output_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e09463",
   "metadata": {},
   "source": [
    "## Applying a Pipeline with `process_signal`\n",
    "\n",
    "Once our pipeline is correctly defined, we apply the `process_signal` method to a demo dataset. Recall that `process_signal` is defined as follows:\n",
    "\n",
    "\n",
    "```python\n",
    "def process_signal(self, data=None, window=None, time_index=None, groupby_index=None,\n",
    "                       feature_columns=None, **kwargs):\n",
    "\n",
    "\t\t...\n",
    "\t\treturn data, feature_columns\n",
    "```\n",
    "\n",
    "`process_signal` accepts as input the following arguments:\n",
    "\n",
    "- `data (pd.Dataframe)` : Dataframe with a column containing signal values.\n",
    "- `window (str)`: Duration of window size, e.g. ('1h').\n",
    "- `time_index (str)`: Name of column in `data` that represents the time index.\n",
    "- `groupby_index (str or list[str])`: List of column names to group together and take the window over.\n",
    "- `feature_columns (list)`: List of columns from the input data that should be considered as features (and not dropped).\n",
    "\n",
    "`process_signal` outputs the following:\n",
    "\n",
    "- `data (pd.Dataframe)`: Dataframe containing output feature values as constructed from the signal\n",
    "- `feature_columns (list)`: list of (generated) feature names.\n",
    "\n",
    "We now apply our pipeline to a toy dataset in the `xvalues`, `yvalues` format. We will define our toy dataset as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "174bb4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>signal_id</th>\n",
       "      <th>xvalues</th>\n",
       "      <th>yvalues</th>\n",
       "      <th>sampling_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 00:00:00, 2020-01-01 00:00:01, 202...</td>\n",
       "      <td>[0.43616983763682876, -0.17662312586241055, 0....</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 01:00:00, 2020-01-01 01:00:01, 202...</td>\n",
       "      <td>[0.8023828754411122, -0.14122063493312714, -0....</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 02:00:00, 2020-01-01 02:00:01, 202...</td>\n",
       "      <td>[-1.3143142430046044, -1.1055740033788437, -0....</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 03:00:00, 2020-01-01 03:00:01, 202...</td>\n",
       "      <td>[-0.45981995520032104, -0.3255426061995603, -0...</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 04:00:00, 2020-01-01 04:00:01, 202...</td>\n",
       "      <td>[-0.6380405111460377, -0.11924167777027689, 0....</td>\n",
       "      <td>1000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  turbine_id        signal_id  \\\n",
       "0       T001  Sensor1_signal1   \n",
       "1       T001  Sensor1_signal1   \n",
       "2       T001  Sensor1_signal1   \n",
       "3       T001  Sensor1_signal1   \n",
       "4       T001  Sensor1_signal1   \n",
       "\n",
       "                                             xvalues  \\\n",
       "0  [2020-01-01 00:00:00, 2020-01-01 00:00:01, 202...   \n",
       "1  [2020-01-01 01:00:00, 2020-01-01 01:00:01, 202...   \n",
       "2  [2020-01-01 02:00:00, 2020-01-01 02:00:01, 202...   \n",
       "3  [2020-01-01 03:00:00, 2020-01-01 03:00:01, 202...   \n",
       "4  [2020-01-01 04:00:00, 2020-01-01 04:00:01, 202...   \n",
       "\n",
       "                                             yvalues  sampling_frequency  \n",
       "0  [0.43616983763682876, -0.17662312586241055, 0....              1000.0  \n",
       "1  [0.8023828754411122, -0.14122063493312714, -0....              1000.0  \n",
       "2  [-1.3143142430046044, -1.1055740033788437, -0....              1000.0  \n",
       "3  [-0.45981995520032104, -0.3255426061995603, -0...              1000.0  \n",
       "4  [-0.6380405111460377, -0.11924167777027689, 0....              1000.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_dataset = get_demo_data()\n",
    "demo_dataset['xvalues'] = demo_dataset['timestamp'].copy()\n",
    "demo_dataset['yvalues'] = demo_dataset['values'].copy()\n",
    "demo_dataset = (demo_dataset.set_index('timestamp').resample(rule = '60T').apply(lambda x: x.to_list())).reset_index()\n",
    "demo_dataset[['turbine_id', 'signal_id', 'sampling_frequency']] = demo_dataset[['turbine_id', 'signal_id', 'sampling_frequency']].apply(lambda x: x[0])\n",
    "demo_dataset = demo_dataset[['turbine_id', 'signal_id', 'xvalues', 'yvalues', 'sampling_frequency']]\n",
    "demo_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2133852",
   "metadata": {},
   "source": [
    "Finally, we apply the `process_signal` method of our previously defined pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82980ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turbine_id</th>\n",
       "      <th>signal_id</th>\n",
       "      <th>xvalues</th>\n",
       "      <th>yvalues</th>\n",
       "      <th>sampling_frequency</th>\n",
       "      <th>identity1.fft1.std1.std_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 00:00:00, 2020-01-01 00:00:01, 202...</td>\n",
       "      <td>[0.43616983763682876, -0.17662312586241055, 0....</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>14.444991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 01:00:00, 2020-01-01 01:00:01, 202...</td>\n",
       "      <td>[0.8023828754411122, -0.14122063493312714, -0....</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>12.326223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 02:00:00, 2020-01-01 02:00:01, 202...</td>\n",
       "      <td>[-1.3143142430046044, -1.1055740033788437, -0....</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>12.051415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 03:00:00, 2020-01-01 03:00:01, 202...</td>\n",
       "      <td>[-0.45981995520032104, -0.3255426061995603, -0...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>10.657243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T001</td>\n",
       "      <td>Sensor1_signal1</td>\n",
       "      <td>[2020-01-01 04:00:00, 2020-01-01 04:00:01, 202...</td>\n",
       "      <td>[-0.6380405111460377, -0.11924167777027689, 0....</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>12.640728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  turbine_id        signal_id  \\\n",
       "0       T001  Sensor1_signal1   \n",
       "1       T001  Sensor1_signal1   \n",
       "2       T001  Sensor1_signal1   \n",
       "3       T001  Sensor1_signal1   \n",
       "4       T001  Sensor1_signal1   \n",
       "\n",
       "                                             xvalues  \\\n",
       "0  [2020-01-01 00:00:00, 2020-01-01 00:00:01, 202...   \n",
       "1  [2020-01-01 01:00:00, 2020-01-01 01:00:01, 202...   \n",
       "2  [2020-01-01 02:00:00, 2020-01-01 02:00:01, 202...   \n",
       "3  [2020-01-01 03:00:00, 2020-01-01 03:00:01, 202...   \n",
       "4  [2020-01-01 04:00:00, 2020-01-01 04:00:01, 202...   \n",
       "\n",
       "                                             yvalues  sampling_frequency  \\\n",
       "0  [0.43616983763682876, -0.17662312586241055, 0....              1000.0   \n",
       "1  [0.8023828754411122, -0.14122063493312714, -0....              1000.0   \n",
       "2  [-1.3143142430046044, -1.1055740033788437, -0....              1000.0   \n",
       "3  [-0.45981995520032104, -0.3255426061995603, -0...              1000.0   \n",
       "4  [-0.6380405111460377, -0.11924167777027689, 0....              1000.0   \n",
       "\n",
       "   identity1.fft1.std1.std_value  \n",
       "0                      14.444991  \n",
       "1                      12.326223  \n",
       "2                      12.051415  \n",
       "3                      10.657243  \n",
       "4                      12.640728  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data, feature_columns = mypipeline.process_signal(demo_dataset, time_index = 'xvalues')\n",
    "\n",
    "processed_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b96ca09",
   "metadata": {},
   "source": [
    "\n",
    "Success! We have managed to apply the primitives to generate features on the input dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590baf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
